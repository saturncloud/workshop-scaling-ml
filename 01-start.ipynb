{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right\" src=\"img/saturn.png\" width=\"300\" />\n",
    "\n",
    "# Scaling Machine Learning in Python\n",
    "\n",
    "## Welcome!\n",
    "\n",
    "In this hands-on workshop, attendees will have the opportunity to see how a standard data science and machine learning workflow using pandas and scikit-learn can be easily parallelized using Dask clusters on Saturn Cloud.\n",
    "\n",
    "After this workshop you will know:\n",
    "- When you need parallel computing for your workflow\n",
    "- How to use Dask Dataframes for loading and cleaning data\n",
    "- How to perform distributed model training with Dask\n",
    "- How to scale a hyperparameter search across a cluster\n",
    "- How to conduct a batch inference task over a cluster\n",
    "\n",
    "\n",
    "#### _Wait!_\n",
    "\n",
    "If you are _**not**_ reading this from inside Jupyter Lab in Saturn Cloud, check out the [README.md](README.md) to set up your account and servers.\n",
    "\n",
    "## Saturn Cloud concepts\n",
    "\n",
    "### Projects\n",
    "\n",
    "A \"Project\" is where all the work done in Saturn Cloud resides. Each user can have multiple projects, and these projects can be shared between users. The hardware associated with each project is called a \"Resource\" and they are organized in the following manner:\n",
    "\n",
    "```\n",
    "└── Project\n",
    "    ├── Jupyter Server (*)\n",
    "    ├── Dask Cluster\n",
    "    ├── Deployment\n",
    "    │   └── Dask Cluster\n",
    "```\n",
    "\n",
    "(*) Every Project has a Jupyter Server, while Dask Clusters and Deployments are optional.\n",
    "\n",
    "### Images\n",
    "\n",
    "An \"Image\" is a Docker image that contains a Python environment to be attached to various Resources. A Project is set to use one Image, and all Resources in that Project will utilize the same Image.\n",
    "\n",
    "Saturn Cloud includes pre-built images for users to get up and running quickly. Users can create custom images by navigating to the \"Images\" tab from the Saturn Cloud UI.\n",
    "\n",
    "### Jupyter Server\n",
    "\n",
    "This resource runs the Jupyter Notebook and Jupyter Lab interfaces. Most time will likely be spent \"inside\" one of these Jupyter interfaces. \n",
    "\n",
    "### Dask Cluster\n",
    "\n",
    "A Dask Cluster can be attached to a Jupyter Server to scale out work. Clusters are composed of a scheduler instance and any number of worker instances. Clusters can be created and started/stopped from the Saturn Cloud UI. The [dask-saturn](https://github.com/saturncloud/dask-saturn) package is the interface for working with Dask Clusters in a notebook or script within a Jupyter Server, and can also be used for starting/stopping the cluster.\n",
    "\n",
    "### Deployment\n",
    "\n",
    "A \"Deployment\" is a resource that is created to serve an always-on or scheduled workload such as serving a machine learning model, hosting a dashboard via a web app, or an ETL job. It utilizes the same project Image and code from the Jupyter Server, and can optional have its own Dask cluster assigned to it.\n",
    "\n",
    "Deployments will not be covered in this workshop.\n",
    "\n",
    "### Code and data files\n",
    "\n",
    "The filesystem of a Jupyter Server is maintained on persistent volumes, so any code or files created/uploaded will remain there after shutting down the server. \n",
    "\n",
    "However, all files are not sent to associated Dask cluster workers or Deployments because those are different machines with their own filesystems. \n",
    "\n",
    "**Code**: Code maintained in the `/home/jovyan/project` folder or through the Repositories feature will be sent to the resources when they are turned on. \n",
    "\n",
    "**Data files**: Data files should be managed outside of Saturn Cloud in systems such as S3 or a database. This ensures each worker in a Dask cluster has access to the data.\n",
    "\n",
    "### Advanced settings\n",
    "\n",
    "Advanced settings for Projects include Environment Variables and Start Scripts. These will not be covered in the workshop, but more information can be found on the [Saturn Cloud docs](https://www.saturncloud.io/docs/getting-started/spinning/jupyter/#advanced-settings).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello world\n",
    "\n",
    "Run the following cell to ensure your Dask cluster is up and running (if it is not yet started, it may take a few minutes to spin up). If you see something like:\n",
    "```\n",
    "[2020-11-05 19:23:55] INFO - dask-saturn | Cluster is ready\n",
    "Hello, world!\n",
    "```\n",
    "as the output, you are ready to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = SaturnCluster()\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(3)\n",
    "\n",
    "print('Hello, world!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access data\n",
    "\n",
    "This workshop will utilize publicly-available [NYC taxi](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) that is hosted on an [S3 bucket](https://registry.opendata.aws/nyc-tlc-trip-records-pds/). No AWS account is required for access. Run the following cell to list the available files in the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "s3.glob('s3://nyc-tlc/trip data/yellow_tripdata_*')[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Some code cells throughout the workshop notebooks will require input based on the concepts being introduced in the notebook. Some cells will have most of the code written out, but indicate places to be filled in. Others will be completely blank and will require you to write a few lines.\n",
    "\n",
    "Try your best to fill in appropriate code and get the cell to run.\n",
    "\n",
    "To check your work (or cheat), expand the cell immediately below it. Make sure to run your cell with the correct code or run the hidden cell, as subsequent cells may depend on it. Try it here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello(name, x):\n",
    "    print(f\"Hello, {name}!\")\n",
    "    print(f\"Your result is: {x + 5}\")\n",
    "    \n",
    "my_name = <YOUR NAME>\n",
    "hello(my_name, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def hello(name, x):\n",
    "    print(f\"Hello, {name}!\")\n",
    "    print(f\"Your result is: {x + 5}\")\n",
    "    \n",
    "my_name = \"Kip\"\n",
    "hello(my_name, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Success!\n",
    "\n",
    "![success](https://media4.giphy.com/media/uTuLngvL9p0Xe/giphy.gif?cid=ecf05e47krvy8flrlqjl7q7mn6f0ju2q7q4jz0upgff7a50z&rid=giphy.gif)\n",
    "\n",
    "Move on to [02-single-node.ipynb](02-single-node.ipynb) to start the workshop content."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
