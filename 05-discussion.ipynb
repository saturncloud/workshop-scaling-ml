{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right\" src=\"img/saturn.png\" width=\"300\" />\n",
    "\n",
    "# Scaling Machine Learning in Python\n",
    "\n",
    "## Discussion\n",
    "\n",
    "In this workshop, we covered:\n",
    "\n",
    "- How to use Dask Dataframes for loading and cleaning data\n",
    "- How to perform distributed model training with Dask\n",
    "- How to scale a hyperparameter search across a cluster\n",
    "- How to conduct a batch inference task over a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask concepts\n",
    "\n",
    "We introduced several key Dask concepts by walking through the machine learning workflows. The workflow examples were specific to the NYC taxi data, but you can utilize these concepts to parallelize just about any use case with Dask.\n",
    "\n",
    "- Initialize Dask: `SaturnCluster` and `Client`\n",
    "- Dask's lazy evaluation: `.compute()`, `.persist()`, and `wait()`\n",
    "- `dask.delayed` functions: when processing doesn't fit into `dask.dataframe` or `dask.array` classes\n",
    "- Dask DataFrames: parallel pandas DataFrames\n",
    "    - `map_partitions`: execute arbitrary functions\n",
    "- Dask Joblib backend: parallelize scikit-learn algorithms\n",
    "- Dask futures: execute functions remotely\n",
    "\n",
    "## Could we use a large Jupyter Server instead of a Dask Cluster?\n",
    "\n",
    "Dask will work with a `LocalCluster` on any sized machine by not passing a cluster to the `Client` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dashboard link displayed here will not load because the Jupyter Server is executing within Saturn Cloud. You can access it via the Jupyter proxy by copying the URL from this JupyterLab browser window and replacing `/lab/*` with `/proxy/8787/status`.\n",
    "\n",
    "In Saturn Cloud, you can get a Jupyter Server with up to 64 cores and 512 GB of memory. However, we recommend using Dask Clusters because they can scale out to many more machines and handle even more computational or data-intensive workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "### RAPIDS\n",
    "\n",
    "[RAPIDS](http://rapids.ai/) is an exciting project that accelerates data science workloads on the GPU, and parallelizes to multiple GPUs with Dask.\n",
    "\n",
    "### Deep learning\n",
    "\n",
    "Dask can scale out popular deep learning tools like TensorFlow and PyTorch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
