{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right\" src=\"img/saturn.png\" width=\"300\" />\n",
    "\n",
    "# Scaling Machine Learning in Python\n",
    "\n",
    "## Large datasets\n",
    "\n",
    "- Load and process large dataset\n",
    "    - `dask.dataframe`\n",
    "- Predict over large dataset\n",
    "    - `ParallelPostFit`\n",
    "    - `map_partitions`\n",
    "- Train model with large dataset\n",
    "    - `Incremental`\n",
    "    - `dask_ml`\n",
    "    - XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and process large dataset\n",
    "\n",
    "## Initialize Dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-09 17:16:05] INFO - dask-saturn | Cluster is ready\n"
     ]
    }
   ],
   "source": [
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = SaturnCluster()\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "s3 = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nyc-tlc/trip data/yellow_tripdata_2019-01.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-02.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-03.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-04.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-05.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-06.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-07.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-08.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-09.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-10.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-11.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-12.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_2019 = 's3://nyc-tlc/trip data/yellow_tripdata_2019-*.csv'\n",
    "s3.glob(files_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.8 ms, sys: 12.4 ms, total: 51.2 ms\n",
      "Wall time: 150 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "taxi = dd.read_csv(\n",
    "    files_2019,\n",
    "    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "    storage_options={'anon': True},\n",
    "    assume_missing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=127</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>float64</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-csv, 127 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                VendorID tpep_pickup_datetime tpep_dropoff_datetime passenger_count trip_distance RatecodeID store_and_fwd_flag PULocationID DOLocationID payment_type fare_amount    extra  mta_tax tip_amount tolls_amount improvement_surcharge total_amount congestion_surcharge\n",
       "npartitions=127                                                                                                                                                                                                                                                                     \n",
       "                 float64       datetime64[ns]        datetime64[ns]         float64       float64    float64             object      float64      float64      float64     float64  float64  float64    float64      float64               float64      float64              float64\n",
       "                     ...                  ...                   ...             ...           ...        ...                ...          ...          ...          ...         ...      ...      ...        ...          ...                   ...          ...                  ...\n",
       "...                  ...                  ...                   ...             ...           ...        ...                ...          ...          ...          ...         ...      ...      ...        ...          ...                   ...          ...                  ...\n",
       "                     ...                  ...                   ...             ...           ...        ...                ...          ...          ...          ...         ...      ...      ...        ...          ...                   ...          ...                  ...\n",
       "                     ...                  ...                   ...             ...           ...        ...                ...          ...          ...          ...         ...      ...      ...        ...          ...                   ...          ...                  ...\n",
       "Dask Name: read-csv, 127 tasks"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dd.Scalar<series-..., dtype=int64>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_bytes = taxi.memory_usage(deep=True).sum()\n",
    "taxi_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 16367.014316\n",
      "CPU times: user 73.7 ms, sys: 753 µs, total: 74.5 ms\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Size (MB): {taxi_bytes.compute() / 1e6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi = taxi.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 69.2 ms, sys: 4.46 ms, total: 73.7 ms\n",
      "Wall time: 30 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = wait(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 16367.014316\n",
      "CPU times: user 46.5 ms, sys: 7.93 ms, total: 54.5 ms\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "taxi_bytes = taxi.memory_usage(deep=True).sum()\n",
    "print(f\"Size (MB): {taxi_bytes.compute() / 1e6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.69 s, sys: 46.9 ms, total: 3.74 s\n",
      "Wall time: 14.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VendorID</th>\n",
       "      <td>84152418.0</td>\n",
       "      <td>1.645</td>\n",
       "      <td>0.498</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_count</th>\n",
       "      <td>84152418.0</td>\n",
       "      <td>1.563</td>\n",
       "      <td>1.208</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_distance</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>3.001</td>\n",
       "      <td>8.091</td>\n",
       "      <td>-37264.53</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.93</td>\n",
       "      <td>8.82</td>\n",
       "      <td>45977.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RatecodeID</th>\n",
       "      <td>84152418.0</td>\n",
       "      <td>1.061</td>\n",
       "      <td>0.760</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PULocationID</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>163.158</td>\n",
       "      <td>66.016</td>\n",
       "      <td>1.00</td>\n",
       "      <td>132.00</td>\n",
       "      <td>162.00</td>\n",
       "      <td>234.00</td>\n",
       "      <td>265.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOLocationID</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>161.353</td>\n",
       "      <td>70.251</td>\n",
       "      <td>1.00</td>\n",
       "      <td>116.00</td>\n",
       "      <td>163.00</td>\n",
       "      <td>236.00</td>\n",
       "      <td>265.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <td>84152418.0</td>\n",
       "      <td>1.289</td>\n",
       "      <td>0.479</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare_amount</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>13.344</td>\n",
       "      <td>174.375</td>\n",
       "      <td>-1856.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>32.04</td>\n",
       "      <td>943274.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>1.087</td>\n",
       "      <td>1.249</td>\n",
       "      <td>-60.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>535.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mta_tax</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>212.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tip_amount</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>2.195</td>\n",
       "      <td>15.657</td>\n",
       "      <td>-221.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.26</td>\n",
       "      <td>141492.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolls_amount</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>0.383</td>\n",
       "      <td>1.817</td>\n",
       "      <td>-70.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3288.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_amount</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>19.124</td>\n",
       "      <td>184.087</td>\n",
       "      <td>-1871.80</td>\n",
       "      <td>11.76</td>\n",
       "      <td>15.80</td>\n",
       "      <td>38.16</td>\n",
       "      <td>1084772.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <td>79543038.0</td>\n",
       "      <td>2.188</td>\n",
       "      <td>0.837</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            count     mean      std       min     25%     50%  \\\n",
       "VendorID               84152418.0    1.645    0.498      1.00    1.00    2.00   \n",
       "passenger_count        84152418.0    1.563    1.208      0.00    1.00    1.00   \n",
       "trip_distance          84399019.0    3.001    8.091 -37264.53    1.07    1.93   \n",
       "RatecodeID             84152418.0    1.061    0.760      1.00    1.00    1.00   \n",
       "PULocationID           84399019.0  163.158   66.016      1.00  132.00  162.00   \n",
       "DOLocationID           84399019.0  161.353   70.251      1.00  116.00  163.00   \n",
       "payment_type           84152418.0    1.289    0.479      1.00    1.00    1.00   \n",
       "fare_amount            84399019.0   13.344  174.375  -1856.00    7.00   11.00   \n",
       "extra                  84399019.0    1.087    1.249    -60.00    0.00    1.00   \n",
       "mta_tax                84399019.0    0.495    0.067     -0.50    0.50    0.50   \n",
       "tip_amount             84399019.0    2.195   15.657   -221.00    0.00    2.06   \n",
       "tolls_amount           84399019.0    0.383    1.817    -70.00    0.00    0.00   \n",
       "improvement_surcharge  84399019.0    0.299    0.028     -0.30    0.30    0.30   \n",
       "total_amount           84399019.0   19.124  184.087  -1871.80   11.76   15.80   \n",
       "congestion_surcharge   79543038.0    2.188    0.837     -2.50    2.50    2.50   \n",
       "\n",
       "                          75%         max  \n",
       "VendorID                 2.00        4.00  \n",
       "passenger_count          2.00        9.00  \n",
       "trip_distance            8.82    45977.22  \n",
       "RatecodeID               1.00       99.00  \n",
       "PULocationID           234.00      265.00  \n",
       "DOLocationID           236.00      265.00  \n",
       "payment_type             2.00        5.00  \n",
       "fare_amount             32.04   943274.80  \n",
       "extra                    3.00      535.38  \n",
       "mta_tax                  0.50      212.42  \n",
       "tip_amount               3.26   141492.02  \n",
       "tolls_amount             0.00     3288.00  \n",
       "improvement_surcharge    0.30        1.00  \n",
       "total_amount            38.16  1084772.17  \n",
       "congestion_surcharge     2.50        4.50  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "taxi_describe = taxi.describe().compute().T\n",
    "np.round(taxi_describe, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify feature and label column names\n",
    "raw_features = [\n",
    "    'tpep_pickup_datetime', \n",
    "    'passenger_count', \n",
    "    'tip_amount', \n",
    "    'fare_amount',\n",
    "]\n",
    "features = [\n",
    "    'pickup_weekday', \n",
    "    'pickup_weekofyear', \n",
    "    'pickup_hour', \n",
    "    'pickup_week_hour', \n",
    "    'pickup_minute', \n",
    "    'passenger_count',\n",
    "]\n",
    "label = 'tip_fraction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(taxi_df):\n",
    "    '''\n",
    "    Generate features from a raw taxi dataframe.\n",
    "    '''\n",
    "    df = taxi_df[taxi_df.fare_amount > 0][raw_features].copy()  # avoid divide-by-zero\n",
    "    df[label] = df.tip_amount / df.fare_amount\n",
    "     \n",
    "    df['pickup_weekday'] = df.tpep_pickup_datetime.dt.weekday\n",
    "    df['pickup_weekofyear'] = df.tpep_pickup_datetime.dt.weekofyear\n",
    "    df['pickup_hour'] = df.tpep_pickup_datetime.dt.hour\n",
    "    df['pickup_week_hour'] = (df.pickup_weekday * 24) + df.pickup_hour\n",
    "    df['pickup_minute'] = df.tpep_pickup_datetime.dt.minute\n",
    "    df = df[features + [label]].astype(float).fillna(-1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_weekday</th>\n",
       "      <th>pickup_weekofyear</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_week_hour</th>\n",
       "      <th>pickup_minute</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>tip_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.235714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_weekday  pickup_weekofyear  pickup_hour  pickup_week_hour  \\\n",
       "0             1.0                1.0          0.0              24.0   \n",
       "1             1.0                1.0          0.0              24.0   \n",
       "2             4.0               51.0         13.0             109.0   \n",
       "3             2.0               48.0         15.0              63.0   \n",
       "4             2.0               48.0         15.0              63.0   \n",
       "\n",
       "   pickup_minute  passenger_count  tip_fraction  \n",
       "0           46.0              1.0      0.235714  \n",
       "1           59.0              1.0      0.071429  \n",
       "2           48.0              3.0      0.000000  \n",
       "3           52.0              5.0      0.000000  \n",
       "4           56.0              5.0      0.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_feat = prep_df(taxi)\n",
    "taxi_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict over large dataset\n",
    "\n",
    "## Previously trained model\n",
    "\n",
    "The [`map_partitions` method](https://docs.dask.org/en/latest/dataframe-api.html#dask.dataframe.Series.map_partitions) allows execution of arbitrary functions on the partitions of the Dask DataFrame. Remember these partitions are just pandas DataFrames, so any code that works with pandas works here! This enables us to execute a function that performs predictions with a pre-trained model.\n",
    "\n",
    "First lets get a handle on how to use the `map_partitions` function with a toy example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab one partition from the Dask DataFrame for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(717801, 7)\n"
     ]
    }
   ],
   "source": [
    "taxi_feat_part = taxi_feat.partitions[0].compute()\n",
    "print(type(taxi_feat_part))\n",
    "print(taxi_feat_part.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(df):\n",
    "    return df['pickup_weekday'] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          5.0\n",
       "1          5.0\n",
       "2         20.0\n",
       "3         10.0\n",
       "4         10.0\n",
       "          ... \n",
       "718872    20.0\n",
       "718873    20.0\n",
       "718874    20.0\n",
       "718875    20.0\n",
       "718876    20.0\n",
       "Name: pickup_weekday, Length: 717801, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(taxi_feat_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = taxi_feat.map_partitions(myfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=127\n",
       "    float64\n",
       "        ...\n",
       "     ...   \n",
       "        ...\n",
       "        ...\n",
       "dtype: float64\n",
       "Dask Name: myfunc, 3810 tasks"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     5.0\n",
       "1     5.0\n",
       "2    20.0\n",
       "3    10.0\n",
       "4    10.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask will attempt to infer the data type of the function used with `map_partitions`. To be more explict, you should pass a `meta=` argument describing the data type of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = taxi_feat.map_partitions(\n",
    "    myfunc,\n",
    "    meta=pd.Series(dtype='float64')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use `map_partitions` to make predictions from a previously trained model. We'll load the model that was trained with scikit-learn and saved in [02-single-node.ipynb](02-single-node.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "\n",
    "model = cloudpickle.load(open('/tmp/model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Write a function that uses the `model` to make a prediction for a given input DataFrame, then execute it with `map_partitions` across the entire `taxi_feat` DataFrame. \n",
    "\n",
    "Assume the input DataFrame already has had features created. The output of the function should be a `pd.Series` object that has predictions for each row in the input DataFrame. Validate that your function works properly by executing it with `taxi_feat_part` as input before trying it with `map_partitions`. The output should look something like:\n",
    "\n",
    "```\n",
    "0         0.164296\n",
    "1         0.166451\n",
    "            ...   \n",
    "717799    0.165269\n",
    "717800    0.168916\n",
    "Length: 717801, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df):\n",
    "    <FILL IN>\n",
    "    \n",
    "preds_sklearn = predict(taxi_feat_part)\n",
    "preds_sklearn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dask = taxi_feat.map_partitions(\n",
    "    <FILL IN>\n",
    ")\n",
    "preds_dask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def predict(df):\n",
    "    preds = model.predict(df[features])\n",
    "    return pd.Series(preds)\n",
    "\n",
    "preds_sklearn = predict(taxi_feat_part)\n",
    "preds_sklearn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "preds_dask = taxi_feat.map_partitions(\n",
    "    predict, \n",
    "    meta=pd.Series(dtype='float64'),\n",
    ")\n",
    "preds_dask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717801"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84194625"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds_dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.453046384464571"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_ml.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(\n",
    "    taxi_feat[label].values, \n",
    "    preds_dask.values, \n",
    "    squared=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ParallelPostFit` wrapper\n",
    "\n",
    "Dask ML also has a [`ParallelPostFit` meta-estimator](https://ml.dask.org/meta-estimators.html) the wraps a scikit-learn model for parallelized predictions. This is useful in scenarios where it is known up-front that a model needs to be trained on a small amount of data but predictions need to be made for a large amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from dask_ml.wrappers import ParallelPostFit\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', ElasticNet(normalize=False, max_iter=100, l1_ratio=0)),\n",
    "])\n",
    "\n",
    "ppf = ParallelPostFit(estimator=pipeline)\n",
    "ppf_fitted = ppf.fit(taxi_feat_part[features], taxi_feat_part[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.453205303896075"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_dask = ppf_fitted.predict(taxi_feat[features])\n",
    "\n",
    "mean_squared_error(\n",
    "    taxi_feat[label].values,\n",
    "    preds_dask, \n",
    "    squared=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with large dataset\n",
    "\n",
    "First, we need to split our `taxi_feat` DataFrame into train/test sets.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Use the [`dask_ml.model_selection.train_test_split` function](https://ml.dask.org/modules/generated/dask_ml.model_selection.train_test_split.html) to split into train and test sets. (Hint: the `dask_ml` function works the same as the `sklearn` function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = <FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    taxi_feat[features], \n",
    "    taxi_feat[label], \n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 218 ms, sys: 31.7 ms, total: 250 ms\n",
      "Wall time: 5.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = dask.persist(\n",
    "    X_train, X_test, y_train, y_test,\n",
    ")\n",
    "_ = wait(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58939024, 58939024)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25255601, 25255601)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask ML models\n",
    "\n",
    "The dask-ml package has parallel implementations of machine learning algorithms that do not have parallel implementations in scikit-learn or other packages. These currently cover linear models and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "from dask_ml.preprocessing import StandardScaler\n",
    "from dask_ml.metrics import mean_squared_error\n",
    "from dask_ml.model_selection import GridSearchCV\n",
    "\n",
    "lr = Pipeline(steps=[\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', LinearRegression(penalty='l2', max_iter=100)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr = X_train.to_dask_array(lengths=True)\n",
    "y_train_arr = y_train.to_dask_array(lengths=True)\n",
    "X_test_arr = X_test.to_dask_array(lengths=True)\n",
    "y_test_arr = y_test.to_dask_array(lengths=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.1 s, sys: 1.04 s, total: 32.2 s\n",
      "Wall time: 7min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr_fitted = lr.fit(\n",
    "    X_train_arr,\n",
    "    y_train_arr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.544812999425133"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_preds = lr_fitted.predict(X_test_arr)\n",
    "mean_squared_error(y_test_arr, lr_preds, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "The `dask-xgboost` package has an integration between XGBoost and Dask that parallelizes model training and prediction across a Dask cluster. \n",
    "\n",
    "> Note: The native XGBoost library also has an integration in the `xgboost.dask` module that will become the recommended approach in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method='approx',\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    n_estimators=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 579 ms, sys: 69.4 ms, total: 649 ms\n",
      "Wall time: 14min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_fitted = xgb.fit(\n",
    "    X_train_arr,\n",
    "    y_train_arr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.536646029575314"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_preds = xgb_fitted.predict(X_test_arr)\n",
    "mean_squared_error(y_test_arr, xgb_preds, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental learning\n",
    "\n",
    "Dask ML can hook into scikit-learn's incremental training features with the [`Incremental` meta-estimator](https://ml.dask.org/incremental.html). Any model that implements a `partial_fit()` method can be utilized with this meta-estimator. We will not cover `Incremental` in this tutorial (`ElasticNet` does not have a `partial_fit()` method). \n",
    "\n",
    "### Scikit-learn models + Joblib\n",
    "\n",
    "For scikit-learn models that have parallel implementations, a joblib backend for Dask can be utilized to train on large datasets. This follows the same process as shown in [03-hyperparameter.ipynb](03-hyperparameter.ipynb), except the work must be done inside a [future](https://docs.dask.org/en/latest/futures.html) to bypass sending all the data through the scheduler. This is outside of the scope of this workshop, but it would look something like:\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from dask.distributed import worker_client\n",
    "import joblib\n",
    "\n",
    "def train_rf():\n",
    "    with worker_client() as client:\n",
    "        X_train, y_train = ...\n",
    "\n",
    "        rf = RandomForestRegressor(max_depth=3, n_estimators=100)\n",
    "        with joblib.parallel_backend('dask', client=client):\n",
    "            rf.fit(X_train, y_train)\n",
    "            \n",
    "        return rf\n",
    "    \n",
    "fut = client.submit(train_rf)\n",
    "fut.result()  # block until function is done\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
