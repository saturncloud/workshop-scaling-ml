{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right\" src=\"img/saturn.png\" width=\"300\" />\n",
    "\n",
    "# Scaling Machine Learning in Python\n",
    "\n",
    "## Large datasets\n",
    "\n",
    "- Load and process large dataset\n",
    "    - `dask.dataframe`\n",
    "- Predict over large dataset\n",
    "    - `ParallelPostFit`\n",
    "    - `map_partitions`\n",
    "- Train model with large dataset\n",
    "    - `Incremental`\n",
    "    - `dask_ml`\n",
    "    - XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and process large dataset\n",
    "\n",
    "## Initialize Dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-09 01:34:31] INFO - dask-saturn | Cluster is ready\n"
     ]
    }
   ],
   "source": [
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = SaturnCluster()\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "s3 = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nyc-tlc/trip data/yellow_tripdata_2019-01.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-02.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-03.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-04.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-05.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-06.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-07.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-08.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-09.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-10.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-11.csv',\n",
       " 'nyc-tlc/trip data/yellow_tripdata_2019-12.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_2019 = 's3://nyc-tlc/trip data/yellow_tripdata_2019-*.csv'\n",
    "s3.glob(files_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 ms, sys: 30.7 ms, total: 52.2 ms\n",
      "Wall time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "taxi = dd.read_csv(\n",
    "    files_2019,\n",
    "    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "    storage_options={'anon': True},\n",
    "    assume_missing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=127</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>float64</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-csv, 127 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                VendorID tpep_pickup_datetime tpep_dropoff_datetime passenger_count trip_distance RatecodeID store_and_fwd_flag PULocationID DOLocationID payment_type fare_amount    extra  mta_tax tip_amount tolls_amount improvement_surcharge total_amount congestion_surcharge\n",
       "npartitions=127                                                                                                                                                                                                                                                                     \n",
       "                 float64       datetime64[ns]        datetime64[ns]         float64       float64    float64             object      float64      float64      float64     float64  float64  float64    float64      float64               float64      float64              float64\n",
       "                     ...                  ...                   ...             ...           ...        ...                ...          ...          ...          ...         ...      ...      ...        ...          ...                   ...          ...                  ...\n",
       "...                  ...                  ...                   ...             ...           ...        ...                ...          ...          ...          ...         ...      ...      ...        ...          ...                   ...          ...                  ...\n",
       "                     ...                  ...                   ...             ...           ...        ...                ...          ...          ...          ...         ...      ...      ...        ...          ...                   ...          ...                  ...\n",
       "                     ...                  ...                   ...             ...           ...        ...                ...          ...          ...          ...         ...      ...      ...        ...          ...                   ...          ...                  ...\n",
       "Dask Name: read-csv, 127 tasks"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dd.Scalar<series-..., dtype=int64>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_bytes = taxi.memory_usage(deep=True).sum()\n",
    "taxi_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 16367.014316\n",
      "CPU times: user 82.9 ms, sys: 9.2 ms, total: 92.1 ms\n",
      "Wall time: 49.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Size (MB): {taxi_bytes.compute() / 1e6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi = taxi.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 74.8 ms, sys: 7.14 ms, total: 82 ms\n",
      "Wall time: 41.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DoneAndNotDoneFutures(done={<Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 0)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 109)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 106)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 53)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 77)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 102)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 28)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 30)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 7)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 73)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 25)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 66)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 65)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 90)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 33)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 32)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 61)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 17)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 50)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 99)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 120)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 54)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 126)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 123)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 3)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 6)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 14)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 116)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 40)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 44)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 76)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 20)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 113)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 11)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 58)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 103)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 82)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 94)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 4)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 83)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 87)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 115)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 47)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 15)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 37)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 91)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 21)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 110)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 112)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 125)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 5)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 86)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 78)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 80)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 45)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 67)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 34)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 107)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 24)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 29)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 55)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 68)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 16)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 81)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 26)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 43)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 92)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 22)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 122)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 69)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 96)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 108)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 84)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 95)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 18)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 111)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 119)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 63)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 74)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 48)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 121)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 59)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 12)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 19)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 62)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 85)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 117)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 72)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 1)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 41)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 118)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 124)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 71)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 52)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 57)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 42)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 114)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 2)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 35)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 98)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 79)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 60)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 64)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 97)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 100)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 13)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 10)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 8)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 23)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 36)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 49)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 104)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 38)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 70)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 93)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 101)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 56)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 9)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 39)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 51)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 31)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 89)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 27)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 75)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 88)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 46)>, <Future: finished, type: pandas.DataFrame, key: ('read-csv-557a801f70790d5b2778996ba671c483', 105)>}, not_done=set())"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "_ = wait(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 16367.014316\n",
      "CPU times: user 51.2 ms, sys: 3.91 ms, total: 55.1 ms\n",
      "Wall time: 2.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "taxi_bytes = taxi.memory_usage(deep=True).sum()\n",
    "print(f\"Size (MB): {taxi_bytes.compute() / 1e6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.46 s, sys: 55.6 ms, total: 3.51 s\n",
      "Wall time: 17.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VendorID</th>\n",
       "      <td>84152418.0</td>\n",
       "      <td>1.645</td>\n",
       "      <td>0.498</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_count</th>\n",
       "      <td>84152418.0</td>\n",
       "      <td>1.563</td>\n",
       "      <td>1.208</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_distance</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>3.001</td>\n",
       "      <td>8.091</td>\n",
       "      <td>-37264.53</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.93</td>\n",
       "      <td>8.82</td>\n",
       "      <td>45977.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RatecodeID</th>\n",
       "      <td>84152418.0</td>\n",
       "      <td>1.061</td>\n",
       "      <td>0.760</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PULocationID</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>163.158</td>\n",
       "      <td>66.016</td>\n",
       "      <td>1.00</td>\n",
       "      <td>132.00</td>\n",
       "      <td>162.00</td>\n",
       "      <td>234.00</td>\n",
       "      <td>265.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOLocationID</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>161.353</td>\n",
       "      <td>70.251</td>\n",
       "      <td>1.00</td>\n",
       "      <td>116.00</td>\n",
       "      <td>163.00</td>\n",
       "      <td>236.00</td>\n",
       "      <td>265.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <td>84152418.0</td>\n",
       "      <td>1.289</td>\n",
       "      <td>0.479</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare_amount</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>13.344</td>\n",
       "      <td>174.375</td>\n",
       "      <td>-1856.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>32.04</td>\n",
       "      <td>943274.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>1.087</td>\n",
       "      <td>1.249</td>\n",
       "      <td>-60.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>535.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mta_tax</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>212.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tip_amount</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>2.195</td>\n",
       "      <td>15.657</td>\n",
       "      <td>-221.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.26</td>\n",
       "      <td>141492.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolls_amount</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>0.383</td>\n",
       "      <td>1.817</td>\n",
       "      <td>-70.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3288.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_amount</th>\n",
       "      <td>84399019.0</td>\n",
       "      <td>19.124</td>\n",
       "      <td>184.087</td>\n",
       "      <td>-1871.80</td>\n",
       "      <td>11.76</td>\n",
       "      <td>15.80</td>\n",
       "      <td>38.16</td>\n",
       "      <td>1084772.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <td>79543038.0</td>\n",
       "      <td>2.188</td>\n",
       "      <td>0.837</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            count     mean      std       min     25%     50%  \\\n",
       "VendorID               84152418.0    1.645    0.498      1.00    1.00    2.00   \n",
       "passenger_count        84152418.0    1.563    1.208      0.00    1.00    1.00   \n",
       "trip_distance          84399019.0    3.001    8.091 -37264.53    1.07    1.93   \n",
       "RatecodeID             84152418.0    1.061    0.760      1.00    1.00    1.00   \n",
       "PULocationID           84399019.0  163.158   66.016      1.00  132.00  162.00   \n",
       "DOLocationID           84399019.0  161.353   70.251      1.00  116.00  163.00   \n",
       "payment_type           84152418.0    1.289    0.479      1.00    1.00    1.00   \n",
       "fare_amount            84399019.0   13.344  174.375  -1856.00    7.00   11.00   \n",
       "extra                  84399019.0    1.087    1.249    -60.00    0.00    1.00   \n",
       "mta_tax                84399019.0    0.495    0.067     -0.50    0.50    0.50   \n",
       "tip_amount             84399019.0    2.195   15.657   -221.00    0.00    2.06   \n",
       "tolls_amount           84399019.0    0.383    1.817    -70.00    0.00    0.00   \n",
       "improvement_surcharge  84399019.0    0.299    0.028     -0.30    0.30    0.30   \n",
       "total_amount           84399019.0   19.124  184.087  -1871.80   11.76   15.80   \n",
       "congestion_surcharge   79543038.0    2.188    0.837     -2.50    2.50    2.50   \n",
       "\n",
       "                          75%         max  \n",
       "VendorID                 2.00        4.00  \n",
       "passenger_count          2.00        9.00  \n",
       "trip_distance            8.82    45977.22  \n",
       "RatecodeID               1.00       99.00  \n",
       "PULocationID           234.00      265.00  \n",
       "DOLocationID           236.00      265.00  \n",
       "payment_type             2.00        5.00  \n",
       "fare_amount             32.04   943274.80  \n",
       "extra                    3.00      535.38  \n",
       "mta_tax                  0.50      212.42  \n",
       "tip_amount               3.26   141492.02  \n",
       "tolls_amount             0.00     3288.00  \n",
       "improvement_surcharge    0.30        1.00  \n",
       "total_amount            38.16  1084772.17  \n",
       "congestion_surcharge     2.50        4.50  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "taxi_describe = taxi.describe().compute().T\n",
    "np.round(taxi_describe, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify feature and label column names\n",
    "raw_features = [\n",
    "    'tpep_pickup_datetime', \n",
    "    'passenger_count', \n",
    "    'tip_amount', \n",
    "    'fare_amount',\n",
    "]\n",
    "features = [\n",
    "    'pickup_weekday', \n",
    "    'pickup_weekofyear', \n",
    "    'pickup_hour', \n",
    "    'pickup_week_hour', \n",
    "    'pickup_minute', \n",
    "    'passenger_count',\n",
    "]\n",
    "label = 'tip_fraction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(taxi_df):\n",
    "    '''\n",
    "    Generate features from a raw taxi dataframe.\n",
    "    '''\n",
    "    df = taxi_df[taxi_df.fare_amount > 0][raw_features].copy()  # avoid divide-by-zero\n",
    "    df[label] = df.tip_amount / df.fare_amount\n",
    "     \n",
    "    df['pickup_weekday'] = df.tpep_pickup_datetime.dt.weekday\n",
    "    df['pickup_weekofyear'] = df.tpep_pickup_datetime.dt.weekofyear\n",
    "    df['pickup_hour'] = df.tpep_pickup_datetime.dt.hour\n",
    "    df['pickup_week_hour'] = (df.pickup_weekday * 24) + df.pickup_hour\n",
    "    df['pickup_minute'] = df.tpep_pickup_datetime.dt.minute\n",
    "    df = df[features + [label]].astype(float).fillna(-1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_weekday</th>\n",
       "      <th>pickup_weekofyear</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_week_hour</th>\n",
       "      <th>pickup_minute</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>tip_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.235714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_weekday  pickup_weekofyear  pickup_hour  pickup_week_hour  \\\n",
       "0             1.0                1.0          0.0              24.0   \n",
       "1             1.0                1.0          0.0              24.0   \n",
       "2             4.0               51.0         13.0             109.0   \n",
       "3             2.0               48.0         15.0              63.0   \n",
       "4             2.0               48.0         15.0              63.0   \n",
       "\n",
       "   pickup_minute  passenger_count  tip_fraction  \n",
       "0           46.0              1.0      0.235714  \n",
       "1           59.0              1.0      0.071429  \n",
       "2           48.0              3.0      0.000000  \n",
       "3           52.0              5.0      0.000000  \n",
       "4           56.0              5.0      0.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_feat = prep_df(taxi)\n",
    "taxi_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    taxi_feat[features], \n",
    "    taxi_feat[label], \n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 299 ms, sys: 16.3 ms, total: 315 ms\n",
      "Wall time: 9.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = dask.persist(\n",
    "    X_train, X_test, y_train, y_test,\n",
    ")\n",
    "_ = wait(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58939024, 58939024)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25255601, 25255601)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict over large dataset\n",
    "\n",
    "## `ParallelPostFit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_feat_sample = taxi_feat.partitions[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(717801, 7)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_feat_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from dask_ml.wrappers import ParallelPostFit\n",
    "from dask_ml.metrics import mean_squared_error\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', ElasticNet(normalize=False, max_iter=100, l1_ratio=0)),\n",
    "])\n",
    "\n",
    "ppf = ParallelPostFit(estimator=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.47 s, sys: 40 ms, total: 1.51 s\n",
      "Wall time: 826 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ppf_fitted = ppf.fit(taxi_feat_sample[features], taxi_feat_sample[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13886918, 0.14424305, 0.11733346, ..., 0.1640145 , 0.17145526,\n",
       "       0.18054951])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppf_fitted.predict(taxi_feat_sample[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ppf_fitted.predict(taxi_feat[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> unknown </td> <td> unknown </td></tr>\n",
       "    <tr><th> Shape </th><td> (nan,) </td> <td> (nan,) </td></tr>\n",
       "    <tr><th> Count </th><td> 3937 Tasks </td><td> 127 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> int64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<_predict, shape=(nan,), dtype=int64, chunksize=(nan,), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13886918, 0.14424305, 0.11733346, ..., 0.1640145 , 0.17145526,\n",
       "       0.18054951])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.blocks[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.453205303896075"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(taxi_feat[label].values, preds, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `map_partitions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.47 s, sys: 31.6 ms, total: 1.5 s\n",
      "Wall time: 818 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fitted = pipeline.fit(\n",
    "    taxi_feat_sample[features], \n",
    "    taxi_feat_sample[label],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "\n",
    "with open('/tmp/model.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cloudpickle.load(open('/tmp/model.pkl', 'rb'))\n",
    "\n",
    "def predict(df):\n",
    "    preds = model.predict(df[features])\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = taxi_feat.map_partitions(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13886918, 0.14424305, 0.11733346, ..., 0.1640145 , 0.17145526,\n",
       "       0.18054951])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.blocks[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.453205303896075"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(taxi_feat[label].values, preds, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with large dataset\n",
    "\n",
    "### `Incremental`\n",
    "\n",
    "\n",
    "https://ml.dask.org/incremental.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `dask_ml.linear_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "from dask_ml.preprocessing import StandardScaler\n",
    "from dask_ml.metrics import mean_squared_error\n",
    "from dask_ml.model_selection import GridSearchCV\n",
    "\n",
    "lr = Pipeline(steps=[\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', LinearRegression(penalty='l2', max_iter=100)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr = X_train.to_dask_array(lengths=True)\n",
    "y_train_arr = y_train.to_dask_array(lengths=True)\n",
    "X_test_arr = X_test.to_dask_array(lengths=True)\n",
    "y_test_arr = y_test.to_dask_array(lengths=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.6 s, sys: 986 ms, total: 33.6 s\n",
      "Wall time: 7min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr_fitted = lr.fit(\n",
    "    X_train_arr,\n",
    "    y_train_arr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.539181569446649"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = fitted.predict(X_test_arr)\n",
    "mean_squared_error(y_test_arr, preds, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "`dask_xgboost` being deprecated soon in favor of `xgboost.dask`. Give example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method='approx',\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    n_estimators=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xgb_fitted = xgb.fit(\n",
    "    X_train_arr,\n",
    "    y_train_arr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.539181569446649"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = fitted.predict(X_test_arr)\n",
    "mean_squared_error(y_test_arr, preds, squared=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
