{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right\" src=\"img/saturn.png\" width=\"300\" />\n",
    "\n",
    "# Scaling Machine Learning in Python\n",
    "\n",
    "## Single-node workflow\n",
    "\n",
    "We'll first start off with a typical data preparation and machine learning workflow utilizing only the Jupyter Server.\n",
    "\n",
    "\n",
    "## Monitor resource utilization\n",
    "\n",
    "For this workshop it's important to monitor CPU and memory utilization when running various commands. It will help with understanding which operations are slow - and which ones run faster on a cluster!\n",
    "\n",
    "To monitor resource utilization of the Jupyter Server, open a new Terminal window inside Jupyter Lab and run `htop`. You can position the window to view the notebook and terminal on the same screen:\n",
    "\n",
    "![htop](img/htop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "This workshop will utilize data for yellow taxi rides from the 2019 calendar year. The machine learning exercises involve predicting the \"tip fraction\" of each ride - how much a rider will tip the driver as a fraction of the charged fare amount.\n",
    "\n",
    "Let's operate with one month for now to explore the data and build out the machine learning code.\n",
    "\n",
    "> Note: `s3.open()` is only required because we're using an anonymous S3 connection. If you have AWS credentials set up, you could pass in just the S3 URL string to `pd.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "s3 = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 687.09 MB\n"
     ]
    }
   ],
   "source": [
    "jan2019_file = 's3://nyc-tlc/trip data/yellow_tripdata_2019-01.csv'\n",
    "jan2019_size = s3.du(jan2019_file)\n",
    "print(f\"Size: {round(jan2019_size / 1e6, 2)} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.3 s, sys: 3.24 s, total: 16.5 s\n",
      "Wall time: 34.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "taxi = pd.read_csv(\n",
    "    s3.open(jan2019_file, mode='rb',),\n",
    "    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:46:40</td>\n",
       "      <td>2019-01-01 00:53:20</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>151</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:59:47</td>\n",
       "      <td>2019-01-01 01:18:59</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-21 13:48:30</td>\n",
       "      <td>2018-12-21 13:52:40</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-28 15:52:25</td>\n",
       "      <td>2018-11-28 15:55:45</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-28 15:56:57</td>\n",
       "      <td>2018-11-28 15:58:33</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>55.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2019-01-01 00:46:40   2019-01-01 00:53:20                1   \n",
       "1         1  2019-01-01 00:59:47   2019-01-01 01:18:59                1   \n",
       "2         2  2018-12-21 13:48:30   2018-12-21 13:52:40                3   \n",
       "3         2  2018-11-28 15:52:25   2018-11-28 15:55:45                5   \n",
       "4         2  2018-11-28 15:56:57   2018-11-28 15:58:33                5   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0            1.5           1                  N           151           239   \n",
       "1            2.6           1                  N           239           246   \n",
       "2            0.0           1                  N           236           236   \n",
       "3            0.0           1                  N           193           193   \n",
       "4            0.0           2                  N           193           193   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1          7.0    0.5      0.5        1.65           0.0   \n",
       "1             1         14.0    0.5      0.5        1.00           0.0   \n",
       "2             1          4.5    0.5      0.5        0.00           0.0   \n",
       "3             2          3.5    0.5      0.5        0.00           0.0   \n",
       "4             2         52.0    0.0      0.5        0.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0                    0.3          9.95                   NaN  \n",
       "1                    0.3         16.30                   NaN  \n",
       "2                    0.3          5.80                   NaN  \n",
       "3                    0.3          7.55                   NaN  \n",
       "4                    0.3         55.55                   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "How many rows are in the `taxi` DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(taxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory usage is also an important consideration, as DataFrames often take more space in memory than on disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 1487.551776\n"
     ]
    }
   ],
   "source": [
    "taxi_bytes = taxi.memory_usage(deep=True).sum()\n",
    "print(f\"Size (MB): {taxi_bytes / 1e6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis\n",
    "\n",
    "For this workshop, we will just look at column statistics. There are many more explorary analyses that can performed with `pandas` and data visualization tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.87 s, sys: 291 ms, total: 4.16 s\n",
      "Wall time: 4.16 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VendorID</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>1.637</td>\n",
       "      <td>0.540</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_count</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>1.567</td>\n",
       "      <td>1.224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_distance</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>2.801</td>\n",
       "      <td>3.738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.80</td>\n",
       "      <td>831.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RatecodeID</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>1.058</td>\n",
       "      <td>0.678</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PULocationID</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>165.501</td>\n",
       "      <td>66.392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.00</td>\n",
       "      <td>162.00</td>\n",
       "      <td>234.00</td>\n",
       "      <td>265.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOLocationID</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>163.753</td>\n",
       "      <td>70.364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113.00</td>\n",
       "      <td>162.00</td>\n",
       "      <td>234.00</td>\n",
       "      <td>265.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>1.292</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare_amount</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>12.409</td>\n",
       "      <td>262.072</td>\n",
       "      <td>-362.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>13.50</td>\n",
       "      <td>623259.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.507</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>535.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mta_tax</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>60.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tip_amount</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>1.827</td>\n",
       "      <td>2.501</td>\n",
       "      <td>-63.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.43</td>\n",
       "      <td>2.33</td>\n",
       "      <td>787.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolls_amount</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>0.317</td>\n",
       "      <td>2.024</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3288.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_amount</th>\n",
       "      <td>7667792.0</td>\n",
       "      <td>15.682</td>\n",
       "      <td>262.293</td>\n",
       "      <td>-362.8</td>\n",
       "      <td>8.19</td>\n",
       "      <td>11.27</td>\n",
       "      <td>16.56</td>\n",
       "      <td>623261.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <td>2811814.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count     mean      std    min     25%     50%  \\\n",
       "VendorID               7667792.0    1.637    0.540    1.0    1.00    2.00   \n",
       "passenger_count        7667792.0    1.567    1.224    0.0    1.00    1.00   \n",
       "trip_distance          7667792.0    2.801    3.738    0.0    0.90    1.53   \n",
       "RatecodeID             7667792.0    1.058    0.678    1.0    1.00    1.00   \n",
       "PULocationID           7667792.0  165.501   66.392    1.0  130.00  162.00   \n",
       "DOLocationID           7667792.0  163.753   70.364    1.0  113.00  162.00   \n",
       "payment_type           7667792.0    1.292    0.473    1.0    1.00    1.00   \n",
       "fare_amount            7667792.0   12.409  262.072 -362.0    6.00    8.50   \n",
       "extra                  7667792.0    0.328    0.507  -60.0    0.00    0.00   \n",
       "mta_tax                7667792.0    0.497    0.053   -0.5    0.50    0.50   \n",
       "tip_amount             7667792.0    1.827    2.501  -63.5    0.00    1.43   \n",
       "tolls_amount           7667792.0    0.317    2.024  -70.0    0.00    0.00   \n",
       "improvement_surcharge  7667792.0    0.299    0.019   -0.3    0.30    0.30   \n",
       "total_amount           7667792.0   15.682  262.293 -362.8    8.19   11.27   \n",
       "congestion_surcharge   2811814.0    0.000    0.009    0.0    0.00    0.00   \n",
       "\n",
       "                          75%        max  \n",
       "VendorID                 2.00       4.00  \n",
       "passenger_count          2.00       9.00  \n",
       "trip_distance            2.80     831.80  \n",
       "RatecodeID               1.00      99.00  \n",
       "PULocationID           234.00     265.00  \n",
       "DOLocationID           234.00     265.00  \n",
       "payment_type             2.00       4.00  \n",
       "fare_amount             13.50  623259.86  \n",
       "extra                    0.50     535.38  \n",
       "mta_tax                  0.50      60.80  \n",
       "tip_amount               2.33     787.25  \n",
       "tolls_amount             0.00    3288.00  \n",
       "improvement_surcharge    0.30       0.60  \n",
       "total_amount            16.56  623261.66  \n",
       "congestion_surcharge     0.00       2.50  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "np.round(taxi.describe().T, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "We are using stateless features, meaning the features values for a given observation don't depend on other observations. This is allows us to create features before performing any data splitting.\n",
    "\n",
    "Then, split data into train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify feature and label column names\n",
    "raw_features = [\n",
    "    'tpep_pickup_datetime', \n",
    "    'passenger_count', \n",
    "    'tip_amount', \n",
    "    'fare_amount',\n",
    "]\n",
    "features = [\n",
    "    'pickup_weekday', \n",
    "    'pickup_weekofyear', \n",
    "    'pickup_hour', \n",
    "    'pickup_week_hour', \n",
    "    'pickup_minute', \n",
    "    'passenger_count',\n",
    "]\n",
    "label = 'tip_fraction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(taxi_df):\n",
    "    '''\n",
    "    Generate features from a raw taxi dataframe.\n",
    "    '''\n",
    "    df = taxi_df[taxi_df.fare_amount > 0][raw_features].copy()  # avoid divide-by-zero\n",
    "    df[label] = df.tip_amount / df.fare_amount\n",
    "     \n",
    "    df['pickup_weekday'] = df.tpep_pickup_datetime.dt.weekday\n",
    "    df['pickup_weekofyear'] = df.tpep_pickup_datetime.dt.weekofyear\n",
    "    df['pickup_hour'] = df.tpep_pickup_datetime.dt.hour\n",
    "    df['pickup_week_hour'] = (df.pickup_weekday * 24) + df.pickup_hour\n",
    "    df['pickup_minute'] = df.tpep_pickup_datetime.dt.minute\n",
    "    df = df[features + [label]].astype(float).fillna(-1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_weekday</th>\n",
       "      <th>pickup_weekofyear</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_week_hour</th>\n",
       "      <th>pickup_minute</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>tip_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.235714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_weekday  pickup_weekofyear  pickup_hour  pickup_week_hour  \\\n",
       "0             1.0                1.0          0.0              24.0   \n",
       "1             1.0                1.0          0.0              24.0   \n",
       "2             4.0               51.0         13.0             109.0   \n",
       "3             2.0               48.0         15.0              63.0   \n",
       "4             2.0               48.0         15.0              63.0   \n",
       "\n",
       "   pickup_minute  passenger_count  tip_fraction  \n",
       "0           46.0              1.0      0.235714  \n",
       "1           59.0              1.0      0.071429  \n",
       "2           48.0              3.0      0.000000  \n",
       "3           52.0              5.0      0.000000  \n",
       "4           56.0              5.0      0.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_feat = prep_df(taxi)\n",
    "taxi_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    taxi_feat[features], \n",
    "    taxi_feat[label], \n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5360764, 6), (5360764,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2297471, 6), (2297471,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "\n",
    "We'll train a linear model to predict `tip_fraction`. We define a `Pipeline` to encompass both feature scaling and model training. This will be useful later when performing a grid search.\n",
    "\n",
    "Evaluate the model against the test set using RMSE. We'll also save out the model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', ElasticNet(normalize=False, max_iter=100, l1_ratio=0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.9 s, sys: 240 ms, total: 14.2 s\n",
      "Wall time: 7.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fitted = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 162 ms, sys: 23.4 ms, total: 185 ms\n",
      "Wall time: 92 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = fitted.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.118045186129104"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, preds, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "\n",
    "with open('/tmp/model.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(fitted, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hooray!\n",
    "\n",
    "We trained a terrible model. But that's okay. The point of this workshop is to scale our work, not make the model perfect!\n",
    "\n",
    "# Let's step things up\n",
    "\n",
    "We were able to train a single, simple model on a sample of the taxi data (single month from 2019). In most model building settings more data and more compute would be required. We will explore the following scenarios where the single-node environment has challenges - and see how Dask solves these problems!\n",
    "\n",
    "- Tune hyperparameters (train numerous models)\n",
    "- Load and process large dataset (full year's data)\n",
    "- Predict over large dataset\n",
    "- Train model with large dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyperparameters\n",
    "\n",
    "Let's stick to the single month of data and try a hyperparameter search. One model can be trained comfortably and fairly quickly with the amount of memory and processing power the Jupyter Server has. A hyperparameter search involves training many models - which means it needs a lot of processing power to finish in a reasonable amount of time.\n",
    "\n",
    "Scikit-learn's `GridSearchCV` accepts an `n_jobs` argument, which will train `n` different models at the same time. Setting it to `-1` uses all the CPU cores in this Jupyter Server. Watch `htop` here - the cores will be saturated while memory will not be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'clf__l1_ratio': np.arange(0, 1.1, 0.1),\n",
    "    'clf__alpha': [0, 0.5, 1, 2],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    params, \n",
    "    cv=3, \n",
    "    n_jobs=-1, \n",
    "    verbose=1, \n",
    "    scoring='neg_mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 44 candidates, totalling 132 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 132 out of 132 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.1 s, sys: 3.6 s, total: 6.7 s\n",
      "Wall time: 4min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-79.51625758585993"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "_ = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This works, but...\n",
    "\n",
    "This is a pretty small grid search. With a larger grid, it would take quite a while.\n",
    "\n",
    "![waiting](https://media3.giphy.com/media/QBd2kLB5qDmysEXre9/giphy.gif?cid=ecf05e47t2wdryi59apjgwa3okzhxpctvxjsqaxautawn96i&rid=giphy.gif)\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process large dataset\n",
    "\n",
    "Let's look at the size of the files on disk using `s3fs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyc-tlc/trip data/yellow_tripdata_2019-01.csv, Size: 687.09 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-02.csv, Size: 649.88 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-03.csv, Size: 726.2 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-04.csv, Size: 689.21 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-05.csv, Size: 701.54 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-06.csv, Size: 643.49 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-07.csv, Size: 584.39 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-08.csv, Size: 562.39 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-09.csv, Size: 608.97 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-10.csv, Size: 669.17 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-11.csv, Size: 637.81 MB\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-12.csv, Size: 639.11 MB\n",
      "\n",
      "Total size: 7.8 GB\n"
     ]
    }
   ],
   "source": [
    "files = s3.glob('s3://nyc-tlc/trip data/yellow_tripdata_2019-*.csv')\n",
    "total_size = 0\n",
    "for f in files:\n",
    "    size = s3.du(f)\n",
    "    total_size += size\n",
    "    \n",
    "    print(f\"{f}, Size: {round(size / 1e6, 2)} MB\")\n",
    "print()\n",
    "print(f\"Total size: {round(total_size / 1e9, 2)} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Files end up taking more space when loaded into memory, but let's see if this will fit on our Jupyter Server. We can loop through the files and concatenate them into one DataFrame. Watch memory utilization as the loop runs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file):\n",
    "    df = pd.read_csv(\n",
    "        s3.open(file, mode='rb'),\n",
    "        parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime']\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    print(f)\n",
    "    df = load_csv(f)\n",
    "    print(f'{len(df)} rows, {df.memory_usage(deep=True).sum() / 1e6} MB')\n",
    "    dfs.append(df)\n",
    "taxi_big = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![explosion](https://media4.giphy.com/media/13d2jHlSlxklVe/giphy.gif)\n",
    "\n",
    "Oh no! Looks like we have enough memory to load the CSV files individually, but not to concatenate them together into one DataFrame.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict over large dataset\n",
    "\n",
    "We can't load a large dataset into one DataFrame, but if we needed to predict over a large dataset we could batch it and collect the results.\n",
    "\n",
    "> Note: If your kernel died when trying to concatenate the big DataFrame, you will need to re-run all the preceding cells in this notebook - just not the one that killed the kernel!\n",
    "\n",
    "This will work, but watch `htop` - only one core will be used at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyc-tlc/trip data/yellow_tripdata_2019-01.csv\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-02.csv\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-03.csv\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-04.csv\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-05.csv\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-06.csv\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-07.csv\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-08.csv\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-09.csv\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-10.csv\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-11.csv\n",
      "nyc-tlc/trip data/yellow_tripdata_2019-12.csv\n",
      "CPU times: user 3min 24s, sys: 28.4 s, total: 3min 52s\n",
      "Wall time: 8min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predicted_dfs = []\n",
    "for f in files:\n",
    "    print(f)\n",
    "    df = load_csv(f)\n",
    "    feat_df = prep_df(df)\n",
    "    predicted = fitted.predict(feat_df[features])\n",
    "    predicted_df = pd.DataFrame(predicted, columns=['prediction'])\n",
    "    predicted_dfs.append(predicted_df)\n",
    "    \n",
    "predicted_full = pd.concat(predicted_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.419462e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.026640e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.385823e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.460668e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.821094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.013440e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.237013e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.564956e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction\n",
       "count  8.419462e+07\n",
       "mean   2.026640e-01\n",
       "std    2.385823e-02\n",
       "min    1.460668e-01\n",
       "25%    1.821094e-01\n",
       "50%    2.013440e-01\n",
       "75%    2.237013e-01\n",
       "max    2.564956e-01"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_full.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Train model with large dataset\n",
    "\n",
    "We are stuck here, because we need to be able to load the full dataset into memory to train with it.\\*\n",
    "\n",
    "Think about all the data we're missing out on. All those models, all those hyperparameters that will never get a chance!\n",
    "\n",
    "<img src=\"https://media0.giphy.com/media/k61nOBRRBMxva/giphy.gif\" width=\"400\" alt=\"crying\" />\n",
    "\n",
    "_\\* Scikit-learn supports [incremental learning](https://scikit-learn.org/stable/modules/computing.html#incremental-learning) for models that have a `partial_fit` method. `ElasticNet` does not have a `partial_fit` method._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There must be a better way!\n",
    "\n",
    "<img src=\"https://docs.dask.org/en/latest/_images/dask_horizontal_no_pad.svg\" width=\"300\" alt=\"dask\" />\n",
    "\n",
    "With Dask, we can scale out to a cluster to address these four failure scenarios. \n",
    "\n",
    "Move on to [03-hyperparameter.ipynb](03-hyperparameter.ipynb) to get started!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
